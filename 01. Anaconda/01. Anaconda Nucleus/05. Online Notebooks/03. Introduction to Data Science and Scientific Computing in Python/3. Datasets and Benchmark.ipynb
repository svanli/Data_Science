{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Datasets and Benchmark\n",
    "\n",
    "Since we are going to play a bit with data and datasets - ultimately to show some examples of data analysis and machine learning - \n",
    "**in this notebook** we will present a quite new package in the Python ecosystem, i.e. `pmlb` that automatically provides datasets for data analysis and Machine Learning.\n",
    "\n",
    "\n",
    "### Don't worry\n",
    "\n",
    "If you are an absolute beginner, or you simply don't know what Machine Learning is, **nothing to worry about**!\n",
    "We will talk about it in the next section! :)\n",
    "\n",
    "**In this notebook** we just focus on the `pmlb` package from a technical perspective. \n",
    "\n",
    "If you are completely new to concepts like **Supervised Learning**, **Classification**, or **Regression** come back to this notebook later after the \"Introduction to Machine Learning\" section for a quick recap and cross-check of these concepts !-)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducting the Penn Machine Learning Benchmarks\n",
    "\n",
    "**Penn Machine Learning Benchmark** (`PMLB`) is a collection of code and data for a large, curated set of benchmark datasets for evaluating and comparing supervised machine learning algorithms. \n",
    "\n",
    "These data sets cover a broad range of applications, and include _binary/multi-class classification_ problems and _regression problems_, as well as combinations of categorical, ordinal, and continuous features. \n",
    "\n",
    "**There are no missing values in these data sets**.\n",
    "\n",
    "PMLB was developed in the [Computational Genetics Lab](http://epistasis.org/) at the [University of Pennsylvania](https://www.upenn.edu/) with funding from the [NIH](http://www.nih.gov/) under grant R01 AI117694. \n",
    "\n",
    "More information here: [github.com/EpistasisLab/penn-ml-benchmarks](https://github.com/EpistasisLab/penn-ml-benchmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set format\n",
    "\n",
    "All data sets are stored in a common format:\n",
    "\n",
    "* First row is the column names\n",
    "* Each following row corresponds to one row of the data\n",
    "* The target column is named `target`\n",
    "* All columns are tab (`\\t`) separated\n",
    "* All files are compressed with `gzip` to conserve space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python wrapper\n",
    "\n",
    "For easy access to the benchmark data sets, we have provided a Python wrapper named `pmlb`. The wrapper can be installed on Python via `pip`:\n",
    "\n",
    "```\n",
    "pip install pmlb\n",
    "```\n",
    "\n",
    "and used in Python scripts as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT ERROR: Please install the pmlb package: pip install pmlb\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    import plmb\n",
    "except ImportError:\n",
    "    print('IMPORT ERROR: Please install the pmlb package: pip install pmlb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pmlb\n",
      "  Downloading pmlb-1.0.1.post3-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pmlb) (6.0)\n",
      "Requirement already satisfied: requests>=2.24.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pmlb) (2.28.1)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from pmlb) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->pmlb) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->pmlb) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->pmlb) (1.21.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pmlb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pmlb) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pmlb) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pmlb) (1.26.11)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.0.5->pmlb) (1.16.0)\n",
      "Installing collected packages: pmlb\n",
      "Successfully installed pmlb-1.0.1.post3\n"
     ]
    }
   ],
   "source": [
    "# if you got an ImportError in the previous cell:\n",
    "\n",
    "!pip install pmlb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset List\n",
    "\n",
    "You can list **all** the available data sets in `pmlb` as it follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Available Datasets: \n",
      "========================\n",
      "1) GAMETES_Epistasis_2_Way_1000atts_0.4H_EDM_1_EDM_1_1\n",
      "2) GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1\n",
      "3) GAMETES_Epistasis_2_Way_20atts_0.4H_EDM_1_1\n",
      "4) GAMETES_Epistasis_3_Way_20atts_0.2H_EDM_1_1\n",
      "5) GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_50_EDM_2_001\n",
      "6) GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_75_EDM_2_001\n",
      "7) Hill_Valley_with_noise\n",
      "8) Hill_Valley_without_noise\n",
      "9) adult\n",
      "10) agaricus_lepiota\n",
      "11) allbp\n",
      "12) allhyper\n",
      "13) allhypo\n",
      "14) allrep\n",
      "15) analcatdata_aids\n",
      "16) analcatdata_asbestos\n",
      "17) analcatdata_authorship\n",
      "18) analcatdata_bankruptcy\n",
      "19) analcatdata_boxing1\n",
      "20) analcatdata_boxing2\n",
      "21) analcatdata_creditscore\n",
      "22) analcatdata_cyyoung8092\n",
      "23) analcatdata_cyyoung9302\n",
      "24) analcatdata_dmft\n",
      "25) analcatdata_fraud\n",
      "26) analcatdata_germangss\n",
      "27) analcatdata_happiness\n",
      "28) analcatdata_japansolvent\n",
      "29) analcatdata_lawsuit\n",
      "30) ann_thyroid\n",
      "31) appendicitis\n",
      "32) australian\n",
      "33) auto\n",
      "34) backache\n",
      "35) balance_scale\n",
      "36) biomed\n",
      "37) breast\n",
      "38) breast_cancer\n",
      "39) breast_cancer_wisconsin\n",
      "40) breast_w\n",
      "41) buggyCrx\n",
      "42) bupa\n",
      "43) calendarDOW\n",
      "44) car\n",
      "45) car_evaluation\n",
      "46) cars\n",
      "47) chess\n",
      "48) churn\n",
      "49) clean1\n",
      "50) clean2\n",
      "51) cleve\n",
      "52) cleveland\n",
      "53) cleveland_nominal\n",
      "54) cloud\n",
      "55) cmc\n",
      "56) coil2000\n",
      "57) colic\n",
      "58) collins\n",
      "59) confidence\n",
      "60) connect_4\n",
      "61) contraceptive\n",
      "62) corral\n",
      "63) credit_a\n",
      "64) credit_g\n",
      "65) crx\n",
      "66) dermatology\n",
      "67) diabetes\n",
      "68) dis\n",
      "69) dna\n",
      "70) ecoli\n",
      "71) fars\n",
      "72) flags\n",
      "73) flare\n",
      "74) german\n",
      "75) glass\n",
      "76) glass2\n",
      "77) haberman\n",
      "78) hayes_roth\n",
      "79) heart_c\n",
      "80) heart_h\n",
      "81) heart_statlog\n",
      "82) hepatitis\n",
      "83) horse_colic\n",
      "84) house_votes_84\n",
      "85) hungarian\n",
      "86) hypothyroid\n",
      "87) ionosphere\n",
      "88) iris\n",
      "89) irish\n",
      "90) kddcup\n",
      "91) kr_vs_kp\n",
      "92) krkopt\n",
      "93) labor\n",
      "94) led24\n",
      "95) led7\n",
      "96) letter\n",
      "97) lupus\n",
      "98) lymphography\n",
      "99) magic\n",
      "100) mfeat_factors\n",
      "101) mfeat_fourier\n",
      "102) mfeat_karhunen\n",
      "103) mfeat_morphological\n",
      "104) mfeat_pixel\n",
      "105) mfeat_zernike\n",
      "106) mnist\n",
      "107) mofn_3_7_10\n",
      "108) molecular_biology_promoters\n",
      "109) monk1\n",
      "110) monk2\n",
      "111) monk3\n",
      "112) movement_libras\n",
      "113) mushroom\n",
      "114) mux6\n",
      "115) new_thyroid\n",
      "116) nursery\n",
      "117) optdigits\n",
      "118) page_blocks\n",
      "119) parity5\n",
      "120) parity5+5\n",
      "121) pendigits\n",
      "122) penguins\n",
      "123) phoneme\n",
      "124) pima\n",
      "125) poker\n",
      "126) postoperative_patient_data\n",
      "127) prnn_crabs\n",
      "128) prnn_fglass\n",
      "129) prnn_synth\n",
      "130) profb\n",
      "131) ring\n",
      "132) saheart\n",
      "133) satimage\n",
      "134) schizo\n",
      "135) segmentation\n",
      "136) shuttle\n",
      "137) sleep\n",
      "138) solar_flare_1\n",
      "139) solar_flare_2\n",
      "140) sonar\n",
      "141) soybean\n",
      "142) spambase\n",
      "143) spect\n",
      "144) spectf\n",
      "145) splice\n",
      "146) tae\n",
      "147) texture\n",
      "148) threeOf9\n",
      "149) tic_tac_toe\n",
      "150) tokyo1\n",
      "151) twonorm\n",
      "152) vehicle\n",
      "153) vote\n",
      "154) vowel\n",
      "155) waveform_21\n",
      "156) waveform_40\n",
      "157) wdbc\n",
      "158) wine_quality_red\n",
      "159) wine_quality_white\n",
      "160) wine_recognition\n",
      "161) xd6\n",
      "162) yeast\n",
      "163) 1027_ESL\n",
      "164) 1028_SWD\n",
      "165) 1029_LEV\n",
      "166) 1030_ERA\n",
      "167) 1089_USCrime\n",
      "168) 1096_FacultySalaries\n",
      "169) 1191_BNG_pbc\n",
      "170) 1193_BNG_lowbwt\n",
      "171) 1196_BNG_pharynx\n",
      "172) 1199_BNG_echoMonths\n",
      "173) 1201_BNG_breastTumor\n",
      "174) 1203_BNG_pwLinear\n",
      "175) 1595_poker\n",
      "176) 192_vineyard\n",
      "177) 195_auto_price\n",
      "178) 197_cpu_act\n",
      "179) 201_pol\n",
      "180) 207_autoPrice\n",
      "181) 210_cloud\n",
      "182) 215_2dplanes\n",
      "183) 218_house_8L\n",
      "184) 225_puma8NH\n",
      "185) 227_cpu_small\n",
      "186) 228_elusage\n",
      "187) 229_pwLinear\n",
      "188) 230_machine_cpu\n",
      "189) 294_satellite_image\n",
      "190) 344_mv\n",
      "191) 4544_GeographicalOriginalofMusic\n",
      "192) 485_analcatdata_vehicle\n",
      "193) 503_wind\n",
      "194) 505_tecator\n",
      "195) 519_vinnie\n",
      "196) 522_pm10\n",
      "197) 523_analcatdata_neavote\n",
      "198) 527_analcatdata_election2000\n",
      "199) 529_pollen\n",
      "200) 537_houses\n",
      "201) 542_pollution\n",
      "202) 547_no2\n",
      "203) 556_analcatdata_apnea2\n",
      "204) 557_analcatdata_apnea1\n",
      "205) 560_bodyfat\n",
      "206) 561_cpu\n",
      "207) 562_cpu_small\n",
      "208) 564_fried\n",
      "209) 573_cpu_act\n",
      "210) 574_house_16H\n",
      "211) 579_fri_c0_250_5\n",
      "212) 581_fri_c3_500_25\n",
      "213) 582_fri_c1_500_25\n",
      "214) 583_fri_c1_1000_50\n",
      "215) 584_fri_c4_500_25\n",
      "216) 586_fri_c3_1000_25\n",
      "217) 588_fri_c4_1000_100\n",
      "218) 589_fri_c2_1000_25\n",
      "219) 590_fri_c0_1000_50\n",
      "220) 591_fri_c1_100_10\n",
      "221) 592_fri_c4_1000_25\n",
      "222) 593_fri_c1_1000_10\n",
      "223) 594_fri_c2_100_5\n",
      "224) 595_fri_c0_1000_10\n",
      "225) 596_fri_c2_250_5\n",
      "226) 597_fri_c2_500_5\n",
      "227) 598_fri_c0_1000_25\n",
      "228) 599_fri_c2_1000_5\n",
      "229) 601_fri_c1_250_5\n",
      "230) 602_fri_c3_250_10\n",
      "231) 603_fri_c0_250_50\n",
      "232) 604_fri_c4_500_10\n",
      "233) 605_fri_c2_250_25\n",
      "234) 606_fri_c2_1000_10\n",
      "235) 607_fri_c4_1000_50\n",
      "236) 608_fri_c3_1000_10\n",
      "237) 609_fri_c0_1000_5\n",
      "238) 611_fri_c3_100_5\n",
      "239) 612_fri_c1_1000_5\n",
      "240) 613_fri_c3_250_5\n",
      "241) 615_fri_c4_250_10\n",
      "242) 616_fri_c4_500_50\n",
      "243) 617_fri_c3_500_5\n",
      "244) 618_fri_c3_1000_50\n",
      "245) 620_fri_c1_1000_25\n",
      "246) 621_fri_c0_100_10\n",
      "247) 622_fri_c2_1000_50\n",
      "248) 623_fri_c4_1000_10\n",
      "249) 624_fri_c0_100_5\n",
      "250) 626_fri_c2_500_50\n",
      "251) 627_fri_c2_500_10\n",
      "252) 628_fri_c3_1000_5\n",
      "253) 631_fri_c1_500_5\n",
      "254) 633_fri_c0_500_25\n",
      "255) 634_fri_c2_100_10\n",
      "256) 635_fri_c0_250_10\n",
      "257) 637_fri_c1_500_50\n",
      "258) 641_fri_c1_500_10\n",
      "259) 643_fri_c2_500_25\n",
      "260) 644_fri_c4_250_25\n",
      "261) 645_fri_c3_500_50\n",
      "262) 646_fri_c3_500_10\n",
      "263) 647_fri_c1_250_10\n",
      "264) 648_fri_c1_250_50\n",
      "265) 649_fri_c0_500_5\n",
      "266) 650_fri_c0_500_50\n",
      "267) 651_fri_c0_100_25\n",
      "268) 653_fri_c0_250_25\n",
      "269) 654_fri_c0_500_10\n",
      "270) 656_fri_c1_100_5\n",
      "271) 657_fri_c2_250_10\n",
      "272) 658_fri_c3_250_25\n",
      "273) 659_sleuth_ex1714\n",
      "274) 663_rabe_266\n",
      "275) 665_sleuth_case2002\n",
      "276) 666_rmftsa_ladata\n",
      "277) 678_visualizing_environmental\n",
      "278) 687_sleuth_ex1605\n",
      "279) 690_visualizing_galaxy\n",
      "280) 695_chatfield_4\n",
      "281) 706_sleuth_case1202\n",
      "282) 712_chscase_geyser1\n",
      "283) banana\n",
      "284) titanic\n"
     ]
    }
   ],
   "source": [
    "from pmlb import dataset_names\n",
    "\n",
    "print('All Available Datasets: ')\n",
    "print('========================')\n",
    "for i, name in enumerate(dataset_names):\n",
    "    print('{}) {}'.format(i+1, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, if you are particularly interested in getting the list of available datasets for **Classification** or **Regression**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Datasets: \n",
      "=========================\n",
      "1) GAMETES_Epistasis_2_Way_1000atts_0.4H_EDM_1_EDM_1_1\n",
      "2) GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1\n",
      "3) GAMETES_Epistasis_2_Way_20atts_0.4H_EDM_1_1\n",
      "4) GAMETES_Epistasis_3_Way_20atts_0.2H_EDM_1_1\n",
      "5) GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_50_EDM_2_001\n",
      "6) GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_75_EDM_2_001\n",
      "7) Hill_Valley_with_noise\n",
      "8) Hill_Valley_without_noise\n",
      "9) adult\n",
      "10) agaricus_lepiota\n",
      "11) allbp\n",
      "12) allhyper\n",
      "13) allhypo\n",
      "14) allrep\n",
      "15) analcatdata_aids\n",
      "16) analcatdata_asbestos\n",
      "17) analcatdata_authorship\n",
      "18) analcatdata_bankruptcy\n",
      "19) analcatdata_boxing1\n",
      "20) analcatdata_boxing2\n",
      "21) analcatdata_creditscore\n",
      "22) analcatdata_cyyoung8092\n",
      "23) analcatdata_cyyoung9302\n",
      "24) analcatdata_dmft\n",
      "25) analcatdata_fraud\n",
      "26) analcatdata_germangss\n",
      "27) analcatdata_happiness\n",
      "28) analcatdata_japansolvent\n",
      "29) analcatdata_lawsuit\n",
      "30) ann_thyroid\n",
      "31) appendicitis\n",
      "32) australian\n",
      "33) auto\n",
      "34) backache\n",
      "35) balance_scale\n",
      "36) biomed\n",
      "37) breast\n",
      "38) breast_cancer\n",
      "39) breast_cancer_wisconsin\n",
      "40) breast_w\n",
      "41) buggyCrx\n",
      "42) bupa\n",
      "43) calendarDOW\n",
      "44) car\n",
      "45) car_evaluation\n",
      "46) cars\n",
      "47) chess\n",
      "48) churn\n",
      "49) clean1\n",
      "50) clean2\n",
      "51) cleve\n",
      "52) cleveland\n",
      "53) cleveland_nominal\n",
      "54) cloud\n",
      "55) cmc\n",
      "56) coil2000\n",
      "57) colic\n",
      "58) collins\n",
      "59) confidence\n",
      "60) connect_4\n",
      "61) contraceptive\n",
      "62) corral\n",
      "63) credit_a\n",
      "64) credit_g\n",
      "65) crx\n",
      "66) dermatology\n",
      "67) diabetes\n",
      "68) dis\n",
      "69) dna\n",
      "70) ecoli\n",
      "71) fars\n",
      "72) flags\n",
      "73) flare\n",
      "74) german\n",
      "75) glass\n",
      "76) glass2\n",
      "77) haberman\n",
      "78) hayes_roth\n",
      "79) heart_c\n",
      "80) heart_h\n",
      "81) heart_statlog\n",
      "82) hepatitis\n",
      "83) horse_colic\n",
      "84) house_votes_84\n",
      "85) hungarian\n",
      "86) hypothyroid\n",
      "87) ionosphere\n",
      "88) iris\n",
      "89) irish\n",
      "90) kddcup\n",
      "91) kr_vs_kp\n",
      "92) krkopt\n",
      "93) labor\n",
      "94) led24\n",
      "95) led7\n",
      "96) letter\n",
      "97) lupus\n",
      "98) lymphography\n",
      "99) magic\n",
      "100) mfeat_factors\n",
      "101) mfeat_fourier\n",
      "102) mfeat_karhunen\n",
      "103) mfeat_morphological\n",
      "104) mfeat_pixel\n",
      "105) mfeat_zernike\n",
      "106) mnist\n",
      "107) mofn_3_7_10\n",
      "108) molecular_biology_promoters\n",
      "109) monk1\n",
      "110) monk2\n",
      "111) monk3\n",
      "112) movement_libras\n",
      "113) mushroom\n",
      "114) mux6\n",
      "115) new_thyroid\n",
      "116) nursery\n",
      "117) optdigits\n",
      "118) page_blocks\n",
      "119) parity5\n",
      "120) parity5+5\n",
      "121) pendigits\n",
      "122) penguins\n",
      "123) phoneme\n",
      "124) pima\n",
      "125) poker\n",
      "126) postoperative_patient_data\n",
      "127) prnn_crabs\n",
      "128) prnn_fglass\n",
      "129) prnn_synth\n",
      "130) profb\n",
      "131) ring\n",
      "132) saheart\n",
      "133) satimage\n",
      "134) schizo\n",
      "135) segmentation\n",
      "136) shuttle\n",
      "137) sleep\n",
      "138) solar_flare_1\n",
      "139) solar_flare_2\n",
      "140) sonar\n",
      "141) soybean\n",
      "142) spambase\n",
      "143) spect\n",
      "144) spectf\n",
      "145) splice\n",
      "146) tae\n",
      "147) texture\n",
      "148) threeOf9\n",
      "149) tic_tac_toe\n",
      "150) tokyo1\n",
      "151) twonorm\n",
      "152) vehicle\n",
      "153) vote\n",
      "154) vowel\n",
      "155) waveform_21\n",
      "156) waveform_40\n",
      "157) wdbc\n",
      "158) wine_quality_red\n",
      "159) wine_quality_white\n",
      "160) wine_recognition\n",
      "161) xd6\n",
      "162) yeast\n"
     ]
    }
   ],
   "source": [
    "from pmlb import classification_dataset_names, regression_dataset_names\n",
    "\n",
    "print('Classification Datasets: ')\n",
    "print('=========================')\n",
    "for i, name in enumerate(classification_dataset_names):\n",
    "    print('{}) {}'.format(i+1, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Datasets: \n",
      "=========================\n",
      "1) 1027_ESL\n",
      "2) 1028_SWD\n",
      "3) 1029_LEV\n",
      "4) 1030_ERA\n",
      "5) 1089_USCrime\n",
      "6) 1096_FacultySalaries\n",
      "7) 1191_BNG_pbc\n",
      "8) 1193_BNG_lowbwt\n",
      "9) 1196_BNG_pharynx\n",
      "10) 1199_BNG_echoMonths\n",
      "11) 1201_BNG_breastTumor\n",
      "12) 1203_BNG_pwLinear\n",
      "13) 1595_poker\n",
      "14) 192_vineyard\n",
      "15) 195_auto_price\n",
      "16) 197_cpu_act\n",
      "17) 201_pol\n",
      "18) 207_autoPrice\n",
      "19) 210_cloud\n",
      "20) 215_2dplanes\n",
      "21) 218_house_8L\n",
      "22) 225_puma8NH\n",
      "23) 227_cpu_small\n",
      "24) 228_elusage\n",
      "25) 229_pwLinear\n",
      "26) 230_machine_cpu\n",
      "27) 294_satellite_image\n",
      "28) 344_mv\n",
      "29) 4544_GeographicalOriginalofMusic\n",
      "30) 485_analcatdata_vehicle\n",
      "31) 503_wind\n",
      "32) 505_tecator\n",
      "33) 519_vinnie\n",
      "34) 522_pm10\n",
      "35) 523_analcatdata_neavote\n",
      "36) 527_analcatdata_election2000\n",
      "37) 529_pollen\n",
      "38) 537_houses\n",
      "39) 542_pollution\n",
      "40) 547_no2\n",
      "41) 556_analcatdata_apnea2\n",
      "42) 557_analcatdata_apnea1\n",
      "43) 560_bodyfat\n",
      "44) 561_cpu\n",
      "45) 562_cpu_small\n",
      "46) 564_fried\n",
      "47) 573_cpu_act\n",
      "48) 574_house_16H\n",
      "49) 579_fri_c0_250_5\n",
      "50) 581_fri_c3_500_25\n",
      "51) 582_fri_c1_500_25\n",
      "52) 583_fri_c1_1000_50\n",
      "53) 584_fri_c4_500_25\n",
      "54) 586_fri_c3_1000_25\n",
      "55) 588_fri_c4_1000_100\n",
      "56) 589_fri_c2_1000_25\n",
      "57) 590_fri_c0_1000_50\n",
      "58) 591_fri_c1_100_10\n",
      "59) 592_fri_c4_1000_25\n",
      "60) 593_fri_c1_1000_10\n",
      "61) 594_fri_c2_100_5\n",
      "62) 595_fri_c0_1000_10\n",
      "63) 596_fri_c2_250_5\n",
      "64) 597_fri_c2_500_5\n",
      "65) 598_fri_c0_1000_25\n",
      "66) 599_fri_c2_1000_5\n",
      "67) 601_fri_c1_250_5\n",
      "68) 602_fri_c3_250_10\n",
      "69) 603_fri_c0_250_50\n",
      "70) 604_fri_c4_500_10\n",
      "71) 605_fri_c2_250_25\n",
      "72) 606_fri_c2_1000_10\n",
      "73) 607_fri_c4_1000_50\n",
      "74) 608_fri_c3_1000_10\n",
      "75) 609_fri_c0_1000_5\n",
      "76) 611_fri_c3_100_5\n",
      "77) 612_fri_c1_1000_5\n",
      "78) 613_fri_c3_250_5\n",
      "79) 615_fri_c4_250_10\n",
      "80) 616_fri_c4_500_50\n",
      "81) 617_fri_c3_500_5\n",
      "82) 618_fri_c3_1000_50\n",
      "83) 620_fri_c1_1000_25\n",
      "84) 621_fri_c0_100_10\n",
      "85) 622_fri_c2_1000_50\n",
      "86) 623_fri_c4_1000_10\n",
      "87) 624_fri_c0_100_5\n",
      "88) 626_fri_c2_500_50\n",
      "89) 627_fri_c2_500_10\n",
      "90) 628_fri_c3_1000_5\n",
      "91) 631_fri_c1_500_5\n",
      "92) 633_fri_c0_500_25\n",
      "93) 634_fri_c2_100_10\n",
      "94) 635_fri_c0_250_10\n",
      "95) 637_fri_c1_500_50\n",
      "96) 641_fri_c1_500_10\n",
      "97) 643_fri_c2_500_25\n",
      "98) 644_fri_c4_250_25\n",
      "99) 645_fri_c3_500_50\n",
      "100) 646_fri_c3_500_10\n",
      "101) 647_fri_c1_250_10\n",
      "102) 648_fri_c1_250_50\n",
      "103) 649_fri_c0_500_5\n",
      "104) 650_fri_c0_500_50\n",
      "105) 651_fri_c0_100_25\n",
      "106) 653_fri_c0_250_25\n",
      "107) 654_fri_c0_500_10\n",
      "108) 656_fri_c1_100_5\n",
      "109) 657_fri_c2_250_10\n",
      "110) 658_fri_c3_250_25\n",
      "111) 659_sleuth_ex1714\n",
      "112) 663_rabe_266\n",
      "113) 665_sleuth_case2002\n",
      "114) 666_rmftsa_ladata\n",
      "115) 678_visualizing_environmental\n",
      "116) 687_sleuth_ex1605\n",
      "117) 690_visualizing_galaxy\n",
      "118) 695_chatfield_4\n",
      "119) 706_sleuth_case1202\n",
      "120) 712_chscase_geyser1\n",
      "121) banana\n",
      "122) titanic\n"
     ]
    }
   ],
   "source": [
    "print('Regression Datasets: ')\n",
    "print('=========================')\n",
    "for i, name in enumerate(regression_dataset_names):\n",
    "    print('{}) {}'.format(i+1, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "←←←←←←←←←←←←←←←←← stopped here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching a Dataset\n",
    "\n",
    "To fetch data from a dataset in `pmlb` it is just necessary the **name** of the dataset. \n",
    "\n",
    "By default, a `pandas.DataFrame` will be returned as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                age     workclass        fnlwgt     education  education-num  \\\n",
      "count  48842.000000  48842.000000  4.884200e+04  48842.000000   48842.000000   \n",
      "mean      38.643585      3.870439  1.896641e+05     10.288420      10.078089   \n",
      "std       13.710510      1.464234  1.056040e+05      3.874492       2.570973   \n",
      "min       17.000000      0.000000  1.228500e+04      0.000000       1.000000   \n",
      "25%       28.000000      4.000000  1.175505e+05      9.000000       9.000000   \n",
      "50%       37.000000      4.000000  1.781445e+05     11.000000      10.000000   \n",
      "75%       48.000000      4.000000  2.376420e+05     12.000000      12.000000   \n",
      "max       90.000000      8.000000  1.490400e+06     15.000000      16.000000   \n",
      "\n",
      "       marital-status    occupation  relationship          race           sex  \\\n",
      "count    48842.000000  48842.000000  48842.000000  48842.000000  48842.000000   \n",
      "mean         2.618750      6.577700      1.443287      3.668052      0.668482   \n",
      "std          1.507703      4.230509      1.602151      0.845986      0.470764   \n",
      "min          0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%          2.000000      3.000000      0.000000      4.000000      0.000000   \n",
      "50%          2.000000      7.000000      1.000000      4.000000      1.000000   \n",
      "75%          4.000000     10.000000      3.000000      4.000000      1.000000   \n",
      "max          6.000000     14.000000      5.000000      4.000000      1.000000   \n",
      "\n",
      "       capital-gain  capital-loss  hours-per-week  native-country  \\\n",
      "count  48842.000000  48842.000000    48842.000000    48842.000000   \n",
      "mean    1079.067626     87.502314       40.422382       36.749355   \n",
      "std     7452.019058    403.004552       12.391444        7.775343   \n",
      "min        0.000000      0.000000        1.000000        0.000000   \n",
      "25%        0.000000      0.000000       40.000000       39.000000   \n",
      "50%        0.000000      0.000000       40.000000       39.000000   \n",
      "75%        0.000000      0.000000       45.000000       39.000000   \n",
      "max    99999.000000   4356.000000       99.000000       41.000000   \n",
      "\n",
      "             target  \n",
      "count  48842.000000  \n",
      "mean       0.760718  \n",
      "std        0.426649  \n",
      "min        0.000000  \n",
      "25%        1.000000  \n",
      "50%        1.000000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Returns a pandas DataFrame\n",
    "from pmlb import fetch_data\n",
    "\n",
    "adult_data = fetch_data('adult')\n",
    "print(adult_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebooks, we will be using this **package** to easily download and use datasets for further analysis and manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feel free to SKIP \n",
    "\n",
    "Please feel free to **skip** the rest of this notebook and come back to it later once we will introduce **NumPy**, and \n",
    "**Scikit-learn** for Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fetch_data` function has two additional parameters:\n",
    "\n",
    "* `return_X_y` (True/False): Whether to return the data in scikit-learn format, with the features and labels stored in separate NumPy arrays.\n",
    "\n",
    "* `local_cache_dir` (string): The directory on your local machine to store the data files so you don't have to fetch them over the web again. By default, the wrapper does not use a local cache directory.\n",
    "\n",
    "For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmlb import fetch_data\n",
    "\n",
    "# Returns NumPy arrays\n",
    "adult_X, adult_y = fetch_data('adult', return_X_y=True, local_cache_dir='./data')\n",
    "print(adult_X)\n",
    "print(adult_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Example usage: Compare two classification algorithms with PMLB\n",
    "\n",
    "PMLB is designed to make it easy to benchmark machine learning algorithms against each other. \n",
    "\n",
    "Below is a Python code snippet showing the most basic way to use PMLB to compare two algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from pmlb import fetch_data, classification_dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_scores = []\n",
    "gnb_test_scores = []\n",
    "\n",
    "for i, classification_dataset in enumerate(classification_dataset_names):\n",
    "    if i > 20:\n",
    "        break\n",
    "        \n",
    "    X, y = fetch_data(classification_dataset, return_X_y=True)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y)\n",
    "\n",
    "    logit = LogisticRegression(solver='liblinear', multi_class='auto', )\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "    logit.fit(train_X, train_y)\n",
    "    gnb.fit(train_X, train_y)\n",
    "\n",
    "    logit_test_scores.append(logit.score(test_X, test_y))\n",
    "    gnb_test_scores.append(gnb.score(test_X, test_y))\n",
    "    print('{} {} DONE'.format(i+1, classification_dataset))\n",
    "\n",
    "sb.boxplot(data=[logit_test_scores, gnb_test_scores], notch=True)\n",
    "plt.xticks([0, 1], ['LogisticRegression', 'GaussianNB'])\n",
    "plt.ylabel('Test Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
