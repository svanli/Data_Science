{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work with data, so the **very first** thing to do is to understand how to **load** data.\n",
    "\n",
    "Data may come in many many formats - and for sure we are not going to cover all the possible scenarios - only the **most common** ones.\n",
    "\n",
    "To do so, we are going to introduce one of the most important library in the Python Scientific ecosystem: `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook:\n",
    "\n",
    "* General introduction to Pandas and `pandas.DataFrame`\n",
    "* Examples of data loading in `CSV` and `JSON` format, using `pandas` built-in functions to handle them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducing Pandas\n",
    "\n",
    "Pandas is the Swiss-Multipurpose Knife for Data Analysis in Python. \n",
    "\n",
    "With Pandas dealing with data-analysis is easy and simple but there are some things you need to get your head around first as **Data-Frames** and **Data-Series**.\n",
    "\n",
    "These structures will be the actual data containers automatically provided by `pandas` to **represent** the data. Once we will be done loading the data, pandas will hold for us a proper container to \n",
    "easily handle the data programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Introduction to Pandas Data Structures\n",
    "\n",
    "Pandas builds on top of two main data structures: **Data Frame** and **Series**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frame _from the outside_\n",
    "\n",
    "From the outside, a Data frame looks like a _Table_ (two dimensional data) in which you will have rows and columns.\n",
    "Each column will have its proper name, and all rows can be easily accessed via position or via **index**, holding reference to each row.\n",
    "\n",
    "<img src=\"images/df_outside.png\" width=\"50%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frame _from the inside_\n",
    "\n",
    "As from the inside, each column of a **Data Frame** will have its proper **data type** (`dtype`) that can be any of basic Python data types or `object`. \n",
    "\n",
    "**Note**: Each Column of a Data Frame in `pandas` is actually a **Data Series**.\n",
    "\n",
    "<img src=\"images/df_inside.png\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data Frame vs Numpy Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "←←←←←←←←←←←←←←←←← stopped here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### Numpy Array\n",
    "\n",
    "<img src=\"./images/ndarray.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Pandas Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/df_inside_numpy.png\" width=\"70%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get Started\n",
    "\n",
    "\n",
    "The following section has been adapted from https://github.com/alanderex/pandas-pydata-2017\n",
    "<span style=\"font-size: small;float: right;\">&copy; 2015-2017 Alexander C.S. Hendorf, <a href=\"http://koenigsweg.com\">Königsweg GmbH</a>, Mannheim </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**import as pd** is a widely used convention\n",
    "\n",
    "\n",
    "In the `data` directory we have some files stored from the *Blooth store*, *let's import one*!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: When you run a command preceded with an excalamation mark (`!`) in a code cell in Jupyter Notebook, that command is interpreted as a **shell command** like in a Terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ./data/blooth_sales_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data in CSV\n",
    "\n",
    "The CSV (Comma Separated Values) is one of the most popular format of data:\n",
    "\n",
    "- each column of data is separated by a comma (or other equivalent and specified separator);\n",
    "- the first row of the file may correspond to column headers;\n",
    "- the first column of each row may correspond to values of the `row index`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read a file in CSV format, `pandas` provide a built-in `read_csv` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = pd.read_csv('./data/blooth_sales_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's explore our data set**\n",
    "\n",
    "**Remember**: First general rule of data analysis: look at the data!\n",
    "\n",
    "The **very** first thing to do after loading a dataset is to **look** at the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10000)  # change presets for data preview\n",
    "sales_data.head(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see what we have got now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sales_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sales_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect your DataFrame with pandas methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**note: floats and ints were detected automatically but date(time) are still strings objects**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *columns*\n",
    "* count rows\n",
    "* data types (numpy)\n",
    "* memenory used\n",
    "\n",
    "**`Strings`** are stored in **`pandas`** as **`object`**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`pandas.read_csv`** has more than 50 parameters to customize imports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example dates can be parsed automatically.\n",
    "\n",
    "> **`parse_dates`** a list of columns to parse for dates.\n",
    "\n",
    "This is only one of multiple options to customize imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = pd.read_csv('./data/blooth_sales_data.csv',\n",
    "                         parse_dates=['birthday', 'orderdate']\n",
    "                        )\n",
    "sales_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The auto date parser is US date friendly by default -> month first! MM/DD/YYYY add *dayfirst=True* for international and European format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = pd.read_csv('./data/blooth_sales_data.csv',\n",
    "                         parse_dates=['birthday', 'orderdate'],\n",
    "                         dayfirst=True)\n",
    "sales_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**!** The date parse is US datew friendly! *MM/DD/YYYY*\n",
    "\n",
    "To use the more common international format for sure,<br>\n",
    "add \n",
    ">**`dayfirst=True`** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CSV import may be highly customized, <br>e.g.:\n",
    "\n",
    "* `date_parser` - which columns to parse.\n",
    "* `compression` - `pandas` hint compression of file, default: `infer`- auto discovery\n",
    "* `delimiter` - delimiter\n",
    "* `thousands`, `decimal` - thousands or decimal character\n",
    "* `encoding` - encoding of the file\n",
    "* `dtype`- target data type of column(s)\n",
    "* `header`- header number(s)\n",
    "* `skipfooter`- do not import the footer (e.g. summary line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading a CSV from URL\n",
    "\n",
    "The `read_csv` function is flexible enough to support reading a CSV file from URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medals_dataset_url = \"http://winterolympicsmedals.com/medals.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medals_data = pd.read_csv(medals_dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medals_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercises\n",
    "\n",
    "Repeat what you just have learned above:\n",
    "* `.head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `.tail()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `.info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the file `blooth_sales_data_2.csv` from the directory *data* and save it to a variable called *data2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the parameters on import to make the import in a useful format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check your import using .info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data with `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take a look at**: \n",
    "\n",
    "- `pd.read_excel`\n",
    "- `pd.read_json`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
