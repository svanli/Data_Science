{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d90d12-1edd-4563-a9ff-ed58bd346b81",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <b>Kaggle Learn</b>\n",
    "# 16. Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b07f93-2ff2-4b25-b861-2a6a2e521f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels as sm\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_rows = 20\n",
    "pd.options.display.max_colwidth = 80\n",
    "np.set_printoptions(precision = 4, suppress = True)\n",
    "from pandas import Series, DataFrame\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddad8d3-fa2b-4917-a138-f5ba82ef92be",
   "metadata": {},
   "source": [
    "## 1. The Convolutional Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc207ae-172c-477e-adf5-a3e61ed49a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Reproducability\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed(31415)\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "warnings.filterwarnings(\"ignore\") # to clean up output cells\n",
    "\n",
    "\n",
    "# Load training and validation sets\n",
    "ds_train_ = image_dataset_from_directory(\n",
    "    '../input/car-or-truck/train',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "ds_valid_ = image_dataset_from_directory(\n",
    "    '../input/car-or-truck/valid',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Data Pipeline\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = (\n",
    "    ds_train_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "ds_valid = (\n",
    "    ds_valid_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f48cd88-c524-48f3-a397-203862a78228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d68bcb-123f-4714-8ed2-4b1855967a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_base = tf.keras.models.load_model(\n",
    "    '../input/cv-course-models/cv-course-models/vgg16-pretrained-base',\n",
    ")\n",
    "pretrained_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0328a9ef-f081-4e42-bf73-6390e700599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    pretrained_base,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(6, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa41e9d-5079-4752-b597-bbf7d10ff92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=30,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496ca62f-9e2c-4093-bfbc-2f27c5c04838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf82790-b506-4a2d-aec2-b1f201a7e9c3",
   "metadata": {},
   "source": [
    "## 2. Convolution and ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd07990-e9e4-45a9-bacd-eef7caad49ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "def show_kernel(kernel, label=True, digits=None, text_size=28):\n",
    "    # Format kernel\n",
    "    kernel = np.array(kernel)\n",
    "    if digits is not None:\n",
    "        kernel = kernel.round(digits)\n",
    "\n",
    "    # Plot kernel\n",
    "    cmap = plt.get_cmap('Blues_r')\n",
    "    plt.imshow(kernel, cmap=cmap)\n",
    "    rows, cols = kernel.shape\n",
    "    thresh = (kernel.max()+kernel.min())/2\n",
    "    # Optionally, add value labels\n",
    "    if label:\n",
    "        for i, j in product(range(rows), range(cols)):\n",
    "            val = kernel[i, j]\n",
    "            color = cmap(0) if val > thresh else cmap(255)\n",
    "            plt.text(j, i, val, \n",
    "                     color=color, size=text_size,\n",
    "                     horizontalalignment='center', verticalalignment='center')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb10431-a3bf-4fdb-9ba0-bb6bcb828cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(filters=64, kernel_size=3), # activation is None\n",
    "    # More layers follow\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89ea389-c84c-4f0a-937f-7848aca72004",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation='relu')\n",
    "    # More layers follow\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17d650-44a6-4d92-9b34-deeabc98bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "\n",
    "image_path = '../input/computer-vision-resources/car_feature.jpg'\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.io.decode_jpeg(image)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(tf.squeeze(image), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98b1204-d976-4ed3-be58-ac9d6352a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "kernel = tf.constant([\n",
    "    [-1, -1, -1],\n",
    "    [-1,  8, -1],\n",
    "    [-1, -1, -1],\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "show_kernel(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba45e3-878b-4e24-96bc-62623105ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat for batch compatibility.\n",
    "image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\n",
    "kernel = tf.cast(kernel, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c5ec0-e449-492e-b790-ca40881fd315",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filter = tf.nn.conv2d(\n",
    "    input=image,\n",
    "    filters=kernel,\n",
    "    # we'll talk about these two in lesson 4!\n",
    "    strides=1,\n",
    "    padding='SAME',\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(tf.squeeze(image_filter))\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175ab90-c6eb-45a5-a3be-728659aceff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_detect = tf.nn.relu(image_filter)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(tf.squeeze(image_detect))\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d93f8e-8301-438e-bda7-7d19791a59e6",
   "metadata": {},
   "source": [
    "## 3. Maximum Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ec7bb-ccae-4668-9957-0897cc1d0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(filters=64, kernel_size=3), # activation is None\n",
    "    layers.MaxPool2D(pool_size=2),\n",
    "    # More layers follow\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a44f8c7-0bae-4f14-a2cb-6b7fe80ec0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "warnings.filterwarnings(\"ignore\") # to clean up output cells\n",
    "\n",
    "# Read image\n",
    "image_path = '../input/computer-vision-resources/car_feature.jpg'\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.io.decode_jpeg(image)\n",
    "\n",
    "# Define kernel\n",
    "kernel = tf.constant([\n",
    "    [-1, -1, -1],\n",
    "    [-1,  8, -1],\n",
    "    [-1, -1, -1],\n",
    "], dtype=tf.float32)\n",
    "\n",
    "# Reformat for batch compatibility.\n",
    "image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\n",
    "\n",
    "# Filter step\n",
    "image_filter = tf.nn.conv2d(\n",
    "    input=image,\n",
    "    filters=kernel,\n",
    "    # we'll talk about these two in the next lesson!\n",
    "    strides=1,\n",
    "    padding='SAME'\n",
    ")\n",
    "\n",
    "# Detect step\n",
    "image_detect = tf.nn.relu(image_filter)\n",
    "\n",
    "# Show what we have so far\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(131)\n",
    "plt.imshow(tf.squeeze(image), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Input')\n",
    "plt.subplot(132)\n",
    "plt.imshow(tf.squeeze(image_filter))\n",
    "plt.axis('off')\n",
    "plt.title('Filter')\n",
    "plt.subplot(133)\n",
    "plt.imshow(tf.squeeze(image_detect))\n",
    "plt.axis('off')\n",
    "plt.title('Detect')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a87615-351d-4d43-8fdc-b27e300d225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "image_condense = tf.nn.pool(\n",
    "    input=image_detect, # image in the Detect step above\n",
    "    window_shape=(2, 2),\n",
    "    pooling_type='MAX',\n",
    "    # we'll see what these do in the next lesson!\n",
    "    strides=(2, 2),\n",
    "    padding='SAME',\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(tf.squeeze(image_condense))\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0b6f42-a545-4099-bba4-591ed2926b48",
   "metadata": {},
   "source": [
    "## 4. The Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6685ef-5ddf-4e76-aa75-f7e7568712b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from skimage import draw, transform\n",
    "\n",
    "def circle(size, val=None, r_shrink=0):\n",
    "    circle = np.zeros([size[0]+1, size[1]+1])\n",
    "    rr, cc = draw.circle_perimeter(\n",
    "        size[0]//2, size[1]//2,\n",
    "        radius=size[0]//2 - r_shrink,\n",
    "        shape=[size[0]+1, size[1]+1],\n",
    "    )\n",
    "    if val is None:\n",
    "        circle[rr, cc] = np.random.uniform(size=circle.shape)[rr, cc]\n",
    "    else:\n",
    "        circle[rr, cc] = val\n",
    "    circle = transform.resize(circle, size, order=0)\n",
    "    return circle\n",
    "\n",
    "def show_kernel(kernel, label=True, digits=None, text_size=28):\n",
    "    # Format kernel\n",
    "    kernel = np.array(kernel)\n",
    "    if digits is not None:\n",
    "        kernel = kernel.round(digits)\n",
    "\n",
    "    # Plot kernel\n",
    "    cmap = plt.get_cmap('Blues_r')\n",
    "    plt.imshow(kernel, cmap=cmap)\n",
    "    rows, cols = kernel.shape\n",
    "    thresh = (kernel.max()+kernel.min())/2\n",
    "    # Optionally, add value labels\n",
    "    if label:\n",
    "        for i, j in product(range(rows), range(cols)):\n",
    "            val = kernel[i, j]\n",
    "            color = cmap(0) if val > thresh else cmap(255)\n",
    "            plt.text(j, i, val, \n",
    "                     color=color, size=text_size,\n",
    "                     horizontalalignment='center', verticalalignment='center')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "def show_extraction(image,\n",
    "                    kernel,\n",
    "                    conv_stride=1,\n",
    "                    conv_padding='valid',\n",
    "                    activation='relu',\n",
    "                    pool_size=2,\n",
    "                    pool_stride=2,\n",
    "                    pool_padding='same',\n",
    "                    figsize=(10, 10),\n",
    "                    subplot_shape=(2, 2),\n",
    "                    ops=['Input', 'Filter', 'Detect', 'Condense'],\n",
    "                    gamma=1.0):\n",
    "    # Create Layers\n",
    "    model = tf.keras.Sequential([\n",
    "                    tf.keras.layers.Conv2D(\n",
    "                        filters=1,\n",
    "                        kernel_size=kernel.shape,\n",
    "                        strides=conv_stride,\n",
    "                        padding=conv_padding,\n",
    "                        use_bias=False,\n",
    "                        input_shape=image.shape,\n",
    "                    ),\n",
    "                    tf.keras.layers.Activation(activation),\n",
    "                    tf.keras.layers.MaxPool2D(\n",
    "                        pool_size=pool_size,\n",
    "                        strides=pool_stride,\n",
    "                        padding=pool_padding,\n",
    "                    ),\n",
    "                   ])\n",
    "\n",
    "    layer_filter, layer_detect, layer_condense = model.layers\n",
    "    kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\n",
    "    layer_filter.set_weights([kernel])\n",
    "\n",
    "    # Format for TF\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32) \n",
    "    \n",
    "    # Extract Feature\n",
    "    image_filter = layer_filter(image)\n",
    "    image_detect = layer_detect(image_filter)\n",
    "    image_condense = layer_condense(image_detect)\n",
    "    \n",
    "    images = {}\n",
    "    if 'Input' in ops:\n",
    "        images.update({'Input': (image, 1.0)})\n",
    "    if 'Filter' in ops:\n",
    "        images.update({'Filter': (image_filter, 1.0)})\n",
    "    if 'Detect' in ops:\n",
    "        images.update({'Detect': (image_detect, gamma)})\n",
    "    if 'Condense' in ops:\n",
    "        images.update({'Condense': (image_condense, gamma)})\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i, title in enumerate(ops):\n",
    "        image, gamma = images[title]\n",
    "        plt.subplot(*subplot_shape, i+1)\n",
    "        plt.imshow(tf.image.adjust_gamma(tf.squeeze(image), gamma))\n",
    "        plt.axis('off')\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdef771a-3943-415f-bf99-de3344103d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(filters=64,\n",
    "                  kernel_size=3,\n",
    "                  strides=1,\n",
    "                  padding='same',\n",
    "                  activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=2,\n",
    "                     strides=1,\n",
    "                     padding='same')\n",
    "    # More layers follow\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf594d2-a795-4dca-ad10-b9a2b77b2a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "\n",
    "image = circle([64, 64], val=1.0, r_shrink=3)\n",
    "image = tf.reshape(image, [*image.shape, 1])\n",
    "# Bottom sobel\n",
    "kernel = tf.constant(\n",
    "    [[-1, -2, -1],\n",
    "     [0, 0, 0],\n",
    "     [1, 2, 1]],\n",
    ")\n",
    "\n",
    "show_kernel(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b2f3b-00e9-4d46-b445-9e63ebbcf98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_extraction(\n",
    "    image, kernel,\n",
    "\n",
    "    # Window parameters\n",
    "    conv_stride=1,\n",
    "    pool_size=2,\n",
    "    pool_stride=2,\n",
    "\n",
    "    subplot_shape=(1, 4),\n",
    "    figsize=(14, 6),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01017d9-e025-411a-972b-6676b85bad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_extraction(\n",
    "    image, kernel,\n",
    "\n",
    "    # Window parameters\n",
    "    conv_stride=3,\n",
    "    pool_size=2,\n",
    "    pool_stride=2,\n",
    "\n",
    "    subplot_shape=(1, 4),\n",
    "    figsize=(14, 6),    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70451175-6a1e-44e1-9840-0b719b7244e0",
   "metadata": {},
   "source": [
    "## 5. Custom Convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29133e5-4b9c-4861-8d9b-d43069bcba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Reproducability\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "warnings.filterwarnings(\"ignore\") # to clean up output cells\n",
    "\n",
    "\n",
    "# Load training and validation sets\n",
    "ds_train_ = image_dataset_from_directory(\n",
    "    '../input/car-or-truck/train',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "ds_valid_ = image_dataset_from_directory(\n",
    "    '../input/car-or-truck/valid',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Data Pipeline\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = (\n",
    "    ds_train_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "ds_valid = (\n",
    "    ds_valid_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc40d2-d1ff-4b61-a105-0b0ff589604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "\n",
    "    # First Convolutional Block\n",
    "    layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\", padding='same',\n",
    "                  # give the input dimensions in the first layer\n",
    "                  # [height, width, color channels(RGB)]\n",
    "                  input_shape=[128, 128, 3]),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Third Convolutional Block\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Classifier Head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units=6, activation=\"relu\"),\n",
    "    layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2d4bf-631d-46bb-a5ec-388bd56c6f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=40,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecdc88a-bd8b-4235-b5b2-ac90ebc6a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763255ec-ea9b-4485-94cc-1c0324072d5c",
   "metadata": {},
   "source": [
    "## 6. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0438f3a1-136e-4d3e-b112-a06b1e1e4c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Reproducability\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    #os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "warnings.filterwarnings(\"ignore\") # to clean up output cells\n",
    "\n",
    "\n",
    "# Load training and validation sets\n",
    "ds_train_ = image_dataset_from_directory(\n",
    "    '../input/car-or-truck/train',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "ds_valid_ = image_dataset_from_directory(\n",
    "    '../input/car-or-truck/valid',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Data Pipeline\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = (\n",
    "    ds_train_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "ds_valid = (\n",
    "    ds_valid_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea83d2-8b51-4d63-8c09-bf58981025d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# these are a new feature in TF 2.2\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "\n",
    "pretrained_base = tf.keras.models.load_model(\n",
    "    '../input/cv-course-models/cv-course-models/vgg16-pretrained-base',\n",
    ")\n",
    "pretrained_base.trainable = False\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # Preprocessing\n",
    "    preprocessing.RandomFlip('horizontal'), # flip left-to-right\n",
    "    preprocessing.RandomContrast(0.5), # contrast change by up to 50%\n",
    "    # Base\n",
    "    pretrained_base,\n",
    "    # Head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(6, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef9cbf-8cf7-4620-89aa-96367b154804",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=30,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aead20-d598-443d-942a-50bca54df48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
